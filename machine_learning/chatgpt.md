# 简介
大预言模型 chatgpt 等相关.

## AI 知识
- 7b: 通常是 GPT-3 模型中的一个版本, 意思是 7 billion parameters, 是拥有 70 亿个参数的模型.

## ChatGPT
聊天生成预训练转换器(Chat Generative Pre-trained Transformer), 是 OpenAI 开发的人工智能聊天机器人. 程序基于 GPT-3.5 架构的大型语言模型并以强化学习训练.

- ChatGLM-6B: 开源、支持中英双语的对话语言模型. [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
- Belle: BE Large Language model Engine 开源中文对话大模型. [LianjiaTechBelle](https://github.com/LianjiaTech/BELLE)
- LoRA: Low-Rank Adaptation of Large Language Models. [microsoft/LoRA](https://github.com/microsoft/LoRA)

## LLM
大型语言模型(LLM, Large Language Model)是基于大数据进行预训练的超大型深度学习模型. 底层转换器是一组神经网络, 这些神经网络由具有自注意力功能的编码器和解码器组成.
- 多模态大模型: 在一个统一的框架下, 集成了多种不同类型数据处理能力的大型神经网络模型. 这些模型能够处理图像、文本、音频等不同的数据模态, 并在这些模态之间进行有效的交互和信息整合.

## 参考
1. [wikipedia - ChatGPT](https://zh.wikipedia.org/zh-tw/ChatGPT)
2. [什么是大型语言模型？](https://aws.amazon.com/cn/what-is/large-language-model/)